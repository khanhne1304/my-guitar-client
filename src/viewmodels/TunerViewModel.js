import { useEffect, useState, useRef, useCallback } from "react";
import { detectPitch } from "../utils/pitchDetection";
import { findClosestNote } from "../models/NoteModel";

export function useTunerViewModel() {
  const [noteData, setNoteData] = useState(null);
  const [rms, setRms] = useState(0);
  const [isRunning, setIsRunning] = useState(false);
  const [error, setError] = useState("");
  const [tunerMode, setTunerMode] = useState("auto"); // "auto" ho·∫∑c "manual"
  const [selectedString, setSelectedString] = useState("E2");

  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const bufferRef = useRef(null);
  const mediaStreamRef = useRef(null);
  const hpFilterRef = useRef(null);
  const lpFilterRef = useRef(null);
  const bandFilterRef = useRef(null);
  const preGainRef = useRef(null);
  const notch50Ref = useRef(null);
  const notch100Ref = useRef(null);
  const rafIdRef = useRef(null);
  const pitchHistory = useRef([]);
  const confidenceHistory = useRef([]);
  const lastPitchRef = useRef(null);
  const stableCountRef = useRef(0);
  const lastStablePitchRef = useRef(null);
  const lastUiUpdateAtRef = useRef(0);
  const currentNoteRef = useRef(null);
  const lastLogAtRef = useRef(0);

  // D·ª´ng micro + d·ªçn d·∫πp
  const stop = useCallback(() => {
    if (rafIdRef.current) cancelAnimationFrame(rafIdRef.current);
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach((t) => t.stop());
      mediaStreamRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close().catch(() => {});
      audioContextRef.current = null;
    }
    setIsRunning(false);
  }, []);

  // H√†m normalize pitch ‚Üí chia 2, chia 3 n·∫øu c·∫ßn
  function normalizePitch(freq) {
    let pitch = freq;
    // n·∫øu pitch cao h∆°n 500Hz ‚Üí c√≥ th·ªÉ l√† harmonic
    while (pitch > 500) pitch = pitch / 2;
    return pitch;
  }

  // ƒê∆∞a t·∫ßn s·ªë v·ªÅ OCTAVE g·∫ßn target nh·∫•t (gi·∫£m sai chi·ªÅu khi c√°ch > 1 octave)
  function normalizeToNearestOctave(freq, target) {
    let f = freq;
    if (!target || !isFinite(target) || target <= 0) return f;
    // K√©o f v·ªÅ sao cho |f - target| l√† nh·ªè nh·∫•t khi nh√¢n/chia 2
    let improved = true;
    while (improved) {
      improved = false;
      if (Math.abs(f * 2 - target) < Math.abs(f - target)) {
        f *= 2;
        improved = true;
        continue;
      }
      if (Math.abs(f / 2 - target) < Math.abs(f - target)) {
        f /= 2;
        improved = true;
      }
    }
    return f;
  }

  // H√†m l·∫•y t·∫ßn s·ªë target c·ªßa d√¢y ƒë√†n
  const getTargetFrequency = useCallback((note) => {
    const FREQUENCIES = {
      E2: 82.41,
      A2: 110.0,
      D3: 146.83,
      G3: 196.0,
      B3: 246.94,
      E4: 329.63,
    };
    return FREQUENCIES[note] || 0;
  }, []);

  const loop = useCallback(() => {
    if (!analyserRef.current || !bufferRef.current) return;
    analyserRef.current.getFloatTimeDomainData(bufferRef.current);

    // 1Ô∏è‚É£ RMS
    let r = 0;
    const buf = bufferRef.current;
    for (let i = 0; i < buf.length; i++) r += buf[i] * buf[i];
    r = Math.sqrt(r / buf.length);
    setRms(r);

    // 2Ô∏è‚É£ Ph√°t hi·ªán pitch v·ªõi confidence score
    const ctx = audioContextRef.current;
    const pitchResult = detectPitch(buf, ctx.sampleRate);

    if (pitchResult && pitchResult.freq) {
      let pitch = normalizePitch(pitchResult.freq);
      const confidence = pitchResult.confidence || 0.5; // Default confidence n·∫øu kh√¥ng c√≥
      const signalRms = pitchResult.rms || 0;

      console.log(
        `üéµ Raw pitch: ${pitchResult.freq.toFixed(2)} Hz ‚Üí Normalized: ${pitch.toFixed(2)} Hz | Confidence: ${(confidence * 100).toFixed(1)}% | RMS: ${signalRms.toFixed(4)}`
      );

      // 3Ô∏è‚É£ Enhanced smoothing v·ªõi confidence weighting
      const MAX_HISTORY = 8; // TƒÉng history ƒë·ªÉ smoothing t·ªët h∆°n
      const MIN_CONFIDENCE = 0.4; // Ch·ªâ nh·∫≠n k·∫øt qu·∫£ c√≥ confidence >= 60%
      
      // Ch·ªâ d√πng khi ƒë·ªß tin c·∫≠y
      if (confidence >= MIN_CONFIDENCE) {
        pitchHistory.current.push(pitch);
        confidenceHistory.current.push(confidence);
      }
      
      if (pitchHistory.current.length > MAX_HISTORY) {
        pitchHistory.current.shift();
        confidenceHistory.current.shift();
      }

      // Weighted average d·ª±a tr√™n confidence
      if (pitchHistory.current.length >= 3) {
        let weightedSum = 0;
        let totalWeight = 0;
        
        for (let i = 0; i < pitchHistory.current.length; i++) {
          const weight = confidenceHistory.current[i] || 0.1;
          weightedSum += pitchHistory.current[i] * weight;
          totalWeight += weight;
        }
        
        const smoothed = weightedSum / totalWeight;

        // Log t·∫ßn s·ªë ƒëang thu (throttled)
        const nowLog = performance.now();
        if (nowLog - lastLogAtRef.current > 100) { // ~10 l·∫ßn/gi√¢y
          lastLogAtRef.current = nowLog;
          console.log(
            `üéôÔ∏è Captured: ${pitchResult.freq.toFixed(2)} Hz | Smoothed: ${smoothed.toFixed(2)} Hz`
          );
        }

        // 4Ô∏è‚É£ Stability check - ch·ªâ c·∫≠p nh·∫≠t khi pitch ·ªïn ƒë·ªãnh
        const STABILITY_THRESHOLD = 2.0; // Hz - tƒÉng ƒë·ªÉ d·ªÖ ·ªïn ƒë·ªãnh h∆°n
        const MIN_STABLE_COUNT = 2; // Gi·∫£m xu·ªëng 2 l·∫ßn ƒë·ªÉ ph·∫£n h·ªìi nhanh h∆°n
        
        if (!lastPitchRef.current || Math.abs(lastPitchRef.current - smoothed) > STABILITY_THRESHOLD) {
          stableCountRef.current = 0;
          lastPitchRef.current = smoothed;
        } else {
          stableCountRef.current++;
        }

        // Ch·ªâ c·∫≠p nh·∫≠t UI khi pitch ƒë√£ ·ªïn ƒë·ªãnh (b·ªè ƒëi·ªÅu ki·ªán confidence)
        if (stableCountRef.current >= MIN_STABLE_COUNT) {
          if (smoothed >= 70 && smoothed <= 500) {
            if (tunerMode === "auto") {
              // Ch·∫ø ƒë·ªô t·ª± ƒë·ªông: detect note g·∫ßn nh·∫•t
              const { note, targetFreq, cents } = findClosestNote(smoothed);

              // Hysteresis tr√°nh nh·∫£y note khi s√°t bi√™n
              const HYSTERESIS_CENTS = 20; // ~1/5 semitone
              const lastNote = currentNoteRef.current;
              let finalNote = note;
              let finalTarget = targetFreq;
              let finalCents = cents;
              if (lastNote && lastNote !== note && noteData?.note === lastNote && Math.abs(cents) < HYSTERESIS_CENTS) {
                finalNote = noteData.note;
                finalTarget = noteData.targetFreq;
                finalCents = 1200 * Math.log2(smoothed / finalTarget);
              }

              // Deadzone ƒë·ªÉ gi·∫£m rung
              const DEADZONE_CENTS = 10;
              if (Math.abs(finalCents) < DEADZONE_CENTS) finalCents = 0;

              console.log(
                `üéØ Auto Mode - Stable: ${smoothed.toFixed(2)} Hz | Note: ${finalNote} | Œî: ${finalCents.toFixed(1)} cents | Conf: ${(confidence * 100).toFixed(1)}%`
              );

              // Throttle c·∫≠p nh·∫≠t UI ~20fps
              const now = performance.now();
              if (now - lastUiUpdateAtRef.current > 50) {
                lastUiUpdateAtRef.current = now;
                setNoteData({ 
                  pitch: smoothed, 
                  note: finalNote, 
                  cents: finalCents, 
                  targetFreq: finalTarget, 
                  confidence,
                  isStable: true 
                });
                currentNoteRef.current = finalNote;
              }
            } else {
              // Ch·∫ø ƒë·ªô manual: so s√°nh v·ªõi d√¢y ƒë√£ ch·ªçn
              const targetFreq = getTargetFrequency(selectedString);
              const aligned = normalizeToNearestOctave(smoothed, targetFreq);
              let cents = 1200 * Math.log2(aligned / targetFreq);

              // Deadzone ƒë·ªÉ gi·∫£m rung
              const DEADZONE_CENTS = 6;
              if (Math.abs(cents) < DEADZONE_CENTS) cents = 0;

              console.log(
                `üéØ Manual Mode - Stable: ${smoothed.toFixed(2)} Hz | Target: ${selectedString} (${targetFreq} Hz) | Œî: ${cents.toFixed(1)} cents | Conf: ${(confidence * 100).toFixed(1)}%`
              );

              const now = performance.now();
              if (now - lastUiUpdateAtRef.current > 50) {
                lastUiUpdateAtRef.current = now;
                setNoteData({ 
                  pitch: smoothed, 
                  note: selectedString, 
                  cents, 
                  targetFreq, 
                  confidence,
                  isStable: true 
                });
              }
            }
            lastStablePitchRef.current = smoothed;
          }
        }
      }
    } else {
      // Kh√¥ng c√≥ pitch detected - reset stability counter
      stableCountRef.current = 0;
    }

    rafIdRef.current = requestAnimationFrame(loop);
  }, [tunerMode, selectedString, getTargetFrequency]);

  const start = useCallback(async () => {
    try {
      setError("");
      stop();

      const AudioCtx = window.AudioContext || window.webkitAudioContext;
      const ctx = new AudioCtx();
      audioContextRef.current = ctx;

      if (ctx.state === "suspended") await ctx.resume();

      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          channelCount: 1,
          sampleRate: 44100, // TƒÉng sample rate ƒë·ªÉ ƒë·ªô ch√≠nh x√°c cao h∆°n
          sampleSize: 16,
        },
      });

      mediaStreamRef.current = stream;
      const source = ctx.createMediaStreamSource(stream);
      // Audio pre-filter chain to improve SNR
      const gain = ctx.createGain();
      gain.gain.value = 1.8; // nh·∫π nh√†ng n√¢ng t√≠n hi·ªáu

      const hp = ctx.createBiquadFilter();
      hp.type = "highpass";
      hp.frequency.value = 80; // cut rumble m·∫°nh h∆°n
      hp.Q.value = 0.707;

      // Notch 50Hz v√† 100Hz ƒë·ªÉ lo·∫°i nhi·ªÖu ƒëi·ªán l∆∞·ªõi
      const notch50 = ctx.createBiquadFilter();
      notch50.type = "notch";
      notch50.frequency.value = 50;
      notch50.Q.value = 12;

      const notch100 = ctx.createBiquadFilter();
      notch100.type = "notch";
      notch100.frequency.value = 100;
      notch100.Q.value = 12;

      const lp = ctx.createBiquadFilter();
      lp.type = "lowpass";
      lp.frequency.value = 550; // limit to guitar band
      lp.Q.value = 0.707;

      const band = ctx.createBiquadFilter();
      band.type = "bandpass";
      band.frequency.value = 200; // broad in auto; will retune in manual
      band.Q.value = 1.2;

      const analyser = ctx.createAnalyser();
      analyser.smoothingTimeConstant = 0.1; // M·ªôt ch√∫t smoothing ƒë·ªÉ gi·∫£m nhi·ªÖu
      analyser.fftSize = 32768; // TƒÉng fftSize ƒë·ªÉ detect fundamental t·ªët h∆°n
      analyser.minDecibels = -90; // Gi·∫£m ng∆∞·ª°ng ƒë·ªÉ b·∫Øt √¢m thanh y·∫øu h∆°n
      analyser.maxDecibels = -10; // Gi·∫£m max ƒë·ªÉ tr√°nh clipping
      analyserRef.current = analyser;
      bufferRef.current = new Float32Array(analyser.fftSize);

      // Reset b·ªô nh·ªõ l·ªçc/stability khi b·∫Øt ƒë·∫ßu l·∫ßn m·ªõi
      pitchHistory.current = [];
      confidenceHistory.current = [];
      lastPitchRef.current = null;
      stableCountRef.current = 0;
      lastStablePitchRef.current = null;
      lastUiUpdateAtRef.current = 0;

      // Wire graph: source -> HPF -> LPF -> Bandpass -> Analyser
      preGainRef.current = gain;
      hpFilterRef.current = hp;
      lpFilterRef.current = lp;
      bandFilterRef.current = band;
      notch50Ref.current = notch50;
      notch100Ref.current = notch100;

      source.connect(gain);
      gain.connect(hp);
      hp.connect(notch50);
      notch50.connect(notch100);
      notch100.connect(lp);
      lp.connect(band);
      band.connect(analyser);
      setIsRunning(true);
      rafIdRef.current = requestAnimationFrame(loop);
    } catch (e) {
      console.error(e);
      setError(e?.message || "Kh√¥ng th·ªÉ truy c·∫≠p micro");
      stop();
    }
  }, [loop, stop]);

  useEffect(() => {
    return () => stop();
  }, [stop]);

  return { 
    noteData, 
    rms, 
    isRunning, 
    error, 
    start, 
    stop,
    tunerMode,
    setTunerMode: (mode) => {
      // Khi ƒë·ªïi ch·∫ø ƒë·ªô, reset b·ªô l·ªçc ƒë·ªÉ tr√°nh k·∫πt tr·∫°ng th√°i c≈©
      pitchHistory.current = [];
      confidenceHistory.current = [];
      lastPitchRef.current = null;
      stableCountRef.current = 0;
      lastStablePitchRef.current = null;
      lastUiUpdateAtRef.current = 0;

      // Auto: bandpass r·ªông; Manual: retune theo d√¢y
      if (bandFilterRef.current) {
        if (mode === "auto") {
          bandFilterRef.current.frequency.value = 200;
          bandFilterRef.current.Q.value = 0.8;
        } else {
          const tf = getTargetFrequency(selectedString);
          bandFilterRef.current.frequency.value = tf || 200;
          bandFilterRef.current.Q.value = 5; // narrow band for stability
        }
      }
      setTunerMode(mode);
    },
    selectedString,
    setSelectedString: (s) => {
      // Khi ƒë·ªïi d√¢y, c≈©ng reset smoothing
      pitchHistory.current = [];
      confidenceHistory.current = [];
      lastPitchRef.current = null;
      stableCountRef.current = 0;
      lastStablePitchRef.current = null;
      lastUiUpdateAtRef.current = 0;
      if (bandFilterRef.current && tunerMode === "manual") {
        const tf = getTargetFrequency(s);
        bandFilterRef.current.frequency.value = tf || 200;
        bandFilterRef.current.Q.value = 5;
      }
      setSelectedString(s);
    }
  };
}
