# T√≠ch h·ª£p Nh·∫≠n di·ªán H·ª£p √¢m v√†o Giao di·ªán

## ‚úÖ C√°c thay ƒë·ªïi ƒë√£ th·ª±c hi·ªán

### 1. C·∫≠p nh·∫≠t Service (`src/services/aiPracticeService.js`)
- ‚úÖ Th√™m method `analyzeAudioWithChords()` ƒë·ªÉ g·ªçi API endpoint m·ªõi

### 2. C·∫≠p nh·∫≠t Component (`src/views/pages/ToolsPage/AIPracticePage/AIPracticePage.jsx`)
- ‚úÖ Thay ƒë·ªïi `handleAnalyze()` ƒë·ªÉ s·ª≠ d·ª•ng `analyzeAudioWithChords()` thay v√¨ `analyzeAudioClip()`
- ‚úÖ Th√™m hi·ªÉn th·ªã card "Nh·∫≠n di·ªán h·ª£p √¢m" v·ªõi:
  - Chord metrics (accuracy, confidence, coverage, s·ªë segments)
  - Timeline c·ªßa predicted chords v·ªõi timestamps v√† confidence
- ‚úÖ C·∫≠p nh·∫≠t text button: "Ph√¢n t√≠ch v·ªõi nh·∫≠n di·ªán h·ª£p √¢m"
- ‚úÖ C·∫≠p nh·∫≠t subtitle ƒë·ªÉ m√¥ t·∫£ ch√≠nh x√°c t√≠nh nƒÉng

### 3. C·∫≠p nh·∫≠t Styles (`AIPracticePage.module.css`)
- ‚úÖ Th√™m styles cho chord metrics display
- ‚úÖ Th√™m styles cho chord timeline/list
- ‚úÖ Responsive design cho c√°c card m·ªõi

## üìä C·∫•u tr√∫c d·ªØ li·ªáu Response

Component hi·ªán nh·∫≠n response v·ªõi c·∫•u tr√∫c:

```javascript
{
  success: true,
  data: {
    file: { originalname, mimetype, size },
    chordRecognition: {
      predicted_chords: [
        { time: 0.0, duration: 4.83, predicted_chord: "B:maj", confidence: 0.58 }
      ],
      metrics: {
        chord_accuracy: 1.0,
        mean_chord_confidence: 0.49,
        chord_coverage: 0.98,
        n_chord_segments: 8
      }
    },
    features: { ... },
    scores: {
      regression: { overall_score: 81.2, ... },
      classification: { level_class: 2 }
    }
  }
}
```

## üé® Giao di·ªán m·ªõi

### Card "Nh·∫≠n di·ªán h·ª£p √¢m"

Hi·ªÉn th·ªã:
1. **Metrics**:
   - ƒê·ªô ch√≠nh x√°c h·ª£p √¢m (n·∫øu c√≥ ground truth)
   - ƒê·ªô tin c·∫≠y trung b√¨nh
   - ƒê·ªô ph·ªß (coverage)
   - S·ªë ƒëo·∫°n h·ª£p √¢m

2. **Timeline**:
   - Danh s√°ch c√°c h·ª£p √¢m ƒë∆∞·ª£c nh·∫≠n di·ªán
   - Timestamp (start - end)
   - T√™n h·ª£p √¢m
   - Confidence score

3. **L∆∞u √Ω**:
   - Hi·ªÉn th·ªã khi kh√¥ng c√≥ ground truth

## üîÑ Workflow

```
User uploads audio
    ‚Üì
Click "Ph√¢n t√≠ch v·ªõi nh·∫≠n di·ªán h·ª£p √¢m"
    ‚Üì
Frontend calls: aiPracticeService.analyzeAudioWithChords()
    ‚Üì
API: POST /api/ai/practice/analyze-with-chords
    ‚Üì
Backend processes with chord recognition
    ‚Üì
Response with chordRecognition + scores
    ‚Üì
UI displays:
  - Overall score card
  - Detailed scores card
  - Chord recognition card (NEW)
  - Explanation card
```

## üìù L∆∞u √Ω

1. **Backward Compatibility**: N·∫øu API kh√¥ng tr·∫£ v·ªÅ `chordRecognition`, card s·∫Ω kh√¥ng hi·ªÉn th·ªã (kh√¥ng g√¢y l·ªói)

2. **Chord Accuracy**: Ch·ªâ hi·ªÉn th·ªã khi c√≥ gi√° tr·ªã > 0 (c√≥ ground truth)

3. **Performance**: Ph√¢n t√≠ch v·ªõi chord recognition m·∫•t th·ªùi gian h∆°n (~2-5 gi√¢y)

4. **Error Handling**: Component x·ª≠ l√Ω l·ªói v√† hi·ªÉn th·ªã message ph√π h·ª£p

## üöÄ C√°ch test

1. Start server v√† client
2. Upload audio file
3. Click "Ph√¢n t√≠ch v·ªõi nh·∫≠n di·ªán h·ª£p √¢m"
4. Ki·ªÉm tra:
   - Card "Nh·∫≠n di·ªán h·ª£p √¢m" hi·ªÉn th·ªã
   - Metrics ƒë∆∞·ª£c hi·ªÉn th·ªã ƒë√∫ng
   - Timeline chords hi·ªÉn th·ªã v·ªõi timestamps
   - Overall score v√† detailed scores v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng

